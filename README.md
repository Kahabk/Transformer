# Transformer
rom-scratch 1M parameter LLM for low-VRAM GPUs (e.g., RTX 2050 4GB). Built with Python/PyTorch, inspired by "Attention Is All You Need." Features custom BPE tokenizer, 8-bit quantization, ~30% FLOP reduction via sparsity. Supports text gen, QA, translation. Trained on WikiText, Common Crawl
